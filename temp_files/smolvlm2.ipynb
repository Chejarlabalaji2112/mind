{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85168dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current RAM usage: 0.07 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil, os\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(f\"Current RAM usage: {process.memory_info().rss / (1024**3):.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb5976",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b8528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/badri/miniconda3/envs/hitomi/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText, pipeline\n",
    "import torch\n",
    "\n",
    "model_path = \"/home/badri/hf/SmolVLM2-500M-Video-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_path,\n",
    "    dtype=torch.float32,\n",
    "    low_cpu_mem_usage=True\n",
    ").to('cpu')\n",
    "\n",
    "pipe = pipeline(\"image-text-to-text\", model=model, processor=processor, max_new_tokens=512, do_sample=False, repetition_penalty=10.03,return_full_text=False)\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea655a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "chat_model = ChatHuggingFace(llm=hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeab1302",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "We detected 1 tokens in the text but no images/videos were passed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     HumanMessage,\n\u001b[32m      3\u001b[39m     SystemMessage,\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m messages = [\n\u001b[32m      7\u001b[39m     SystemMessage(content=\u001b[33m\"\u001b[39m\u001b[33mYou\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre a helpful assistant\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      8\u001b[39m     HumanMessage(\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     ),\n\u001b[32m     13\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m ai_msg = \u001b[43mchat_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1023\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     **kwargs: Any,\n\u001b[32m   1021\u001b[39m ) -> LLMResult:\n\u001b[32m   1022\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:840\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    839\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    848\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1089\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/langchain_huggingface/chat_models/huggingface.py:586\u001b[39m, in \u001b[36mChatHuggingFace._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[39m\n\u001b[32m    582\u001b[39m     stream_iter = \u001b[38;5;28mself\u001b[39m.llm._stream(\n\u001b[32m    583\u001b[39m         llm_input, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m    584\u001b[39m     )\n\u001b[32m    585\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m llm_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mllm_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._to_chat_result(llm_result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/langchain_huggingface/llms/huggingface_pipeline.py:323\u001b[39m, in \u001b[36mHuggingFacePipeline._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m batch_prompts = prompts[i : i + \u001b[38;5;28mself\u001b[39m.batch_size]\n\u001b[32m    322\u001b[39m \u001b[38;5;66;03m# Process batch of prompts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m responses = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# Process each response in the batch\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(responses):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/transformers/pipelines/image_text_to_text.py:371\u001b[39m, in \u001b[36mImageTextToTextPipeline.__call__\u001b[39m\u001b[34m(self, images, text, **kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_images(images):\n\u001b[32m    364\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    Supports the following format\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m    - {\"image\": image, \"text\": text}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    369\u001b[39m \u001b[33;03m    This is a common pattern in other multimodal pipelines, so we support it here as well.\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# encourage the user to use the chat format if supported\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.processor, \u001b[33m\"\u001b[39m\u001b[33mchat_template\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/transformers/pipelines/base.py:1448\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1445\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1446\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1447\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/transformers/pipelines/pt_utils.py:126\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/transformers/pipelines/pt_utils.py:126\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/transformers/pipelines/pt_utils.py:19\u001b[39m, in \u001b[36mPipelineDataset.__getitem__\u001b[39m\u001b[34m(self, i)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[32m     18\u001b[39m     item = \u001b[38;5;28mself\u001b[39m.dataset[i]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/transformers/pipelines/image_text_to_text.py:418\u001b[39m, in \u001b[36mImageTextToTextPipeline.preprocess\u001b[39m\u001b[34m(self, inputs, timeout, continue_final_message, **processing_kwargs)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) > \u001b[32m1\u001b[39m:\n\u001b[32m    417\u001b[39m     processing_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mpadding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m model_inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprocessing_kwargs\u001b[49m\u001b[43m)\u001b[49m.to(\n\u001b[32m    419\u001b[39m     dtype=\u001b[38;5;28mself\u001b[39m.dtype\n\u001b[32m    420\u001b[39m )\n\u001b[32m    422\u001b[39m model_inputs[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m] = inputs_text\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_inputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hitomi/lib/python3.13/site-packages/transformers/models/smolvlm/processing_smolvlm.py:321\u001b[39m, in \u001b[36mSmolVLMProcessor.__call__\u001b[39m\u001b[34m(self, images, text, audio, videos, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m     n_images_in_text = \u001b[38;5;28msum\u001b[39m([sample.count(\u001b[38;5;28mself\u001b[39m.image_token) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m text])\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_images_in_text > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m videos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWe detected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_images_in_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tokens in the text but no images/videos were passed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m inputs = {}\n\u001b[32m    324\u001b[39m \u001b[38;5;66;03m# Images and videos are mutually exclusive, so process one which is present\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: We detected 1 tokens in the text but no images/videos were passed"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "        {\"type\": \"image\", \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe this image?\"},]\n",
    "    ),\n",
    "]\n",
    "\n",
    "ai_msg = chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ddd88e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a Python code snippet that calculates the sum of all numbers in an array using recursion. The function takes two arguments, `arr` and its length (`n`):\n",
      "\n",
      "1) If there are no elements left to process (i .e., if arr[0] == None), return n as it's already included at index [length-2]. Otherwise call this recursive method with new parameters for each element from start until end === -(len+3). This will give us back our original list without any duplicates or extra space complexity issues since we're not creating additional arrays but rather iterating through them one by step while maintaining order.. \n",
      "   ```python\n",
      "   def calculate_sums():\n",
      "       # Base case\n",
      "       \n",
      "     elif len([x]) <= i :\n",
      "         print(\"No more values\")\n",
      "          \n",
      "      else {\n",
      "          result += x + calcSumOfSums()\n",
      "             }\n",
      "   \n",
      " \n",
      "    \n",
      "    results=calculate sums(); \n",
      "    answer+=result;\n",
      "\n",
      "   \"\"\"print('The final value',answer);\"\"\"\n",
      "\n",
      "\n",
      "754896/(((((a*b)+c)*d)*(f*(g)))+(h))/(k * l )**m **p ^ q / r^t\n",
      "                  where p > k>l >= m>=r < t<q\n",
      "\n",
      "              \n",
      " val=(val)**(-y)- ((value)^z)/(w-(v)(u)). Where y , z & w represent different variables depending on how many times you want your calculation repeated etc... So here I have used only three variable which can be changed according required number......... But still these calculations should work fine! Also note about 'o' ! It means odd position so when calculating multiple positions like above then o would mean even positon hence calculated correctly!! And also remember base condition has been added before starting looping over entire data set!!! Because every time after adding some operation inside loops first thing must always happen once because otherwise computation might go wrong due missing operations sometimes!!!! Please let me know what exactly u need help doing? Or just ask anything regarding python programming language itself ????! üòäüòã‚ú®‚ù§Ô∏è ‚úå‚ô• üíñ Thank You In Advance :) @JayeshBharat@jbhbarath j bh baratha | www dot b h Bharathan|wwwdotBHBarathi||https://twitter#orignal || https // instagram//original&lt ;--->><<-- >>>>>> --> <<----->----- -> ---::------:-~ ~\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6756c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The model 'SmolVLMForConditionalGeneration' is not supported for text-generation. Supported models are ['PeftModelForCausalLM', 'ApertusForCausalLM', 'ArceeForCausalLM', 'AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BitNetForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV2ForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'DogeForCausalLM', 'Dots1ForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'Ernie4_5ForCausalLM', 'Ernie4_5_MoeForCausalLM', 'Exaone4ForCausalLM', 'FalconForCausalLM', 'FalconH1ForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'Gemma3nForConditionalGeneration', 'Gemma3nForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'Glm4MoeForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GptOssForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeHybridForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'HunYuanDenseV1ForCausalLM', 'HunYuanMoEV1ForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'Lfm2ForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MiniMaxForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'ModernBertDecoderForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'SeedOssForCausalLM', 'SmolLM3ForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'xLSTMForCausalLM', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>System: <end_of_utterance>\n",
      "User: <end_of_utterance>\n",
      "Assistant: Here is a Python code snippet that calculates the sum of all numbers in a list:\n",
      "\n",
      "```python\n",
      "def sum_of_numbers(lst):\n",
      "    total = 0\n",
      "    for num in lst:\n",
      "        total += num\n",
      "    return total\n",
      "\n",
      "# Example usage\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "result = sum_of_numbers(numbers)\n",
      "print(result)  # Output: 15\n",
      "```\n",
      "\n",
      "In this code, the `sum_of_numbers` function takes a list `lst` as input and initializes a variable `total` to 0. It then iterates over each element `num` in the list using a `for` loop. For each element, it adds it to the `total` variable using the `+=` operator. Finally, the function returns the `total` value.\n",
      "\n",
      "In the example usage, we create a list `numbers` with some sample numbers, and then call the `sum_of_numbers` function with this list as an argument. The function returns the sum of all the numbers in the list, which is 15 in this case.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Use text generation task instead\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,  # processor includes tokenizer\n",
    "    max_new_tokens=256,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "hf = HuggingFacePipeline(pipeline=pipe)\n",
    "chat_model = ChatHuggingFace(llm=hf)\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(content=\"What happens when an unstoppable force meets an immovable object?\")\n",
    "]\n",
    "\n",
    "ai_msg = chat_model.invoke(messages)\n",
    "print(ai_msg.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c0b205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question:{question}\n",
    "Answer: The answer is\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | hf\n",
    "\n",
    "question = \"who is issac newton?\"\n",
    "\n",
    "result = chain.invoke({\"question\":question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bc44a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<|im_start|>User: <end_of_utterance>\\nAssistant: Here is a Python code snippet that calculates the sum of all numbers in an array using recursion and memoization. The function `sum_array` takes two arguments, which are both arrays or lists containing integers (or other data types). It returns another list with only non-negative elements from each input sequence as they appear consecutively within their respective sequences\\' subsequences when combined into one single sorted output vector for better performance on large inputs due to caching benefits provided by dynamic programming techniques like Memoize() used here instead! \\n  \\n  ```python\\n   def calculateSum(arr1):\\n       # Base case - if there\\'s no more than zero items left then return arr[0]\\n           result = [None]*len([x+yfor x,(a,)in enumerate((i)[:])if i>2][::3], y=max({abs(_)-min(-_)})*4**n))\\n       \\n        \\n    \\n    \\n   \\n    print(\"The Sum Of All Elements In An Array Using Recursive Approach\") \\n    n=[5,[6],[7]]\\n\\n    answer=(calculateArray())\\n\\n      \\n     \\n\\n   **Output:** \\n\\n      \"Answer : {answer}\"\\n\\n\\n ### Explanation & Analysis\\n\\n  * This recursive approach uses nested loops where inner loop iterates over sublists while outer iteration checks whether any element exists at least once inside its subtree before adding it back onto our final solution set after checking against possible duplicates through max(). We use \\'memoise(\\'\\')\\', indicating we have already calculated this value so do not need further computation again until needed elsewhere.. Also note how I\\'ve defined my own variable names (\\'result\\',\\'sublist\\'), but you can replace them according your preference depending upon coding style guidelines etc... . Lastly , remember these values will be computed based off current state hence don\\'t forget about initializing variables properly !!! üòäüòã‚ú®‚ù§Ô∏è ‚úå\\u200d‚ôÇ/ üíª#MemoTimeline##DynamicProgramming###Recursivesolution ##PythonScriptingTipsAndTricksForLearning And Practicing On Online Courses || YouTube Videos For Learning | Coding Tutorials To Learn Programming Languages From Scratch Or Intermediate Level With Examples @ Coursera|| Data Science Interview Questions Answers + Tips By Expertise \\\\ufe9\\\\ubd8 ee|Coding TutorialsToLearnDataScienceWithExamplesInHtmlCSSJavaFscriptReactJSNodeJSDocumentsTestingCodeExampleOfHowYouCanUseAjaxOrGetResponseFromServerUsingXMLHttp' additional_kwargs={} response_metadata={} id='run--e5167451-875a-4b7c-94ac-c0d5853d51f3-0'\n"
     ]
    }
   ],
   "source": [
    "print(chat_model.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02030d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<|im_start|>User: <end_of_utterance>\n",
      "Assistant: Here is a Python code snippet that calculates the sum of all numbers in an array using recursion and memoization. The function `sum_array` takes two arguments, which are both arrays or lists containing integers (or other data types). It returns another list with only non-negative elements from each input sequence as they appear consecutively within their respective sequences' subsequences when combined into one single sorted output vector for better performance on large inputs due to caching benefits provided by dynamic programming techniques like Memoize() used here instead! \n",
      "  \n",
      "  ```python\n",
      "   def calculateSum(arr1):\n",
      "       # Base case - if there's no more than zero items left then return arr[0]\n",
      "           result = [None]*len([x+yfor x,(a,)in enumerate((i)[:])if i>2][::3], y=max({abs(_)-min(-_)})*4**n))\n",
      "       \n",
      "        \n",
      "    \n",
      "    \n",
      "   \n",
      "    print(\"The Sum Of All Elements In An Array Using Recursive Approach\") \n",
      "    n=[5,[6],[7]]\n",
      "\n",
      "    answer=(calculateArray())\n",
      "\n",
      "      \n",
      "     \n",
      "\n",
      "   **Output:** \n",
      "\n",
      "      \"Answer : {answer}\"\n",
      "\n",
      "\n",
      " ### Explanation & Analysis\n",
      "\n",
      "  * This recursive approach uses nested loops where inner loop iterates over sublists while outer iteration checks whether any element exists at least once inside its subtree before adding it back onto our final solution set after checking against possible duplicates through max(). We use 'memoise('')', indicating we have already calculated this value so do not need further computation again until needed elsewhere.. Also note how I've defined my own variable names ('result','sublist'), but you can replace them according your preference depending upon coding style guidelines etc... . Lastly , remember these values will be computed based off current state hence don't forget about initializing variables properly !!! üòäüòã‚ú®‚ù§Ô∏è ‚úå‚Äç‚ôÇ/ üíª#MemoTimeline##DynamicProgramming###Recursivesolution ##PythonScriptingTipsAndTricksForLearning And Practicing On Online Courses || YouTube Videos For Learning | Coding Tutorials To Learn Programming Languages From Scratch Or Intermediate Level With Examples @ Coursera|| Data Science Interview Questions Answers + Tips By Expertise \\ufe9\\ubd8 ee|Coding TutorialsToLearnDataScienceWithExamplesInHtmlCSSJavaFscriptReactJSNodeJSDocumentsTestingCodeExampleOfHowYouCanUseAjaxOrGetResponseFromServerUsingXMLHttp' additional_kwargs={} response_metadata={} id='run--e5167451-875a-4b7c-94ac-c0d5853d51f3-0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"content='<|im_start|>User: <end_of_utterance>\\nAssistant: Here is a Python code snippet that calculates the sum of all numbers in an array using recursion and memoization. The function `sum_array` takes two arguments, which are both arrays or lists containing integers (or other data types). It returns another list with only non-negative elements from each input sequence as they appear consecutively within their respective sequences\\' subsequences when combined into one single sorted output vector for better performance on large inputs due to caching benefits provided by dynamic programming techniques like Memoize() used here instead! \\n  \\n  ```python\\n   def calculateSum(arr1):\\n       # Base case - if there\\'s no more than zero items left then return arr[0]\\n           result = [None]*len([x+yfor x,(a,)in enumerate((i)[:])if i>2][::3], y=max({abs(_)-min(-_)})*4**n))\\n       \\n        \\n    \\n    \\n   \\n    print(\"The Sum Of All Elements In An Array Using Recursive Approach\") \\n    n=[5,[6],[7]]\\n\\n    answer=(calculateArray())\\n\\n      \\n     \\n\\n   **Output:** \\n\\n      \"Answer : {answer}\"\\n\\n\\n ### Explanation & Analysis\\n\\n  * This recursive approach uses nested loops where inner loop iterates over sublists while outer iteration checks whether any element exists at least once inside its subtree before adding it back onto our final solution set after checking against possible duplicates through max(). We use \\'memoise(\\'\\')\\', indicating we have already calculated this value so do not need further computation again until needed elsewhere.. Also note how I\\'ve defined my own variable names (\\'result\\',\\'sublist\\'), but you can replace them according your preference depending upon coding style guidelines etc... . Lastly , remember these values will be computed based off current state hence don\\'t forget about initializing variables properly !!! üòäüòã‚ú®‚ù§Ô∏è ‚úå\\u200d‚ôÇ/ üíª#MemoTimeline##DynamicProgramming###Recursivesolution ##PythonScriptingTipsAndTricksForLearning And Practicing On Online Courses || YouTube Videos For Learning | Coding Tutorials To Learn Programming Languages From Scratch Or Intermediate Level With Examples @ Coursera|| Data Science Interview Questions Answers + Tips By Expertise \\\\ufe9\\\\ubd8 ee|Coding TutorialsToLearnDataScienceWithExamplesInHtmlCSSJavaFscriptReactJSNodeJSDocumentsTestingCodeExampleOfHowYouCanUseAjaxOrGetResponseFromServerUsingXMLHttp' additional_kwargs={} response_metadata={} id='run--e5167451-875a-4b7c-94ac-c0d5853d51f3-0'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b7fa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current RAM usage: 0.42 GB\n"
     ]
    }
   ],
   "source": [
    "process = psutil.Process(os.getpid())\n",
    "print(f\"Current RAM usage: {process.memory_info().rss / (1024**3):.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725fda59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "\n",
      "\n",
      "describe the image?\n",
      "Assistant: The image is a certificate from the Indian Institute of Technology (IIT) Madras, dated January 2023. The certificate is for the NPTEL Online Certification for the Joy of Computing using Python. The certificate is awarded to CHEJARLA BALAJI for successfully completing the course\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": \"/home/badri/Pictures/nptel.jpeg\"},\n",
    "            {\"type\": \"text\", \"text\": \"describe the image?\"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Prepare inputs for CPU\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cpu\", dtype=torch.float32)  # CPU + float32\n",
    "\n",
    "# Generate text on CPU\n",
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=64)\n",
    "\n",
    "# Decode output\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "print(generated_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f351e8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hitomi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
